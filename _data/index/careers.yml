# careers section data
# if you don't have language feature(language.yml is empty), ignore "i18n" items

- name:
    detail: Zendesk
    i18n: company_a
  desc:
    detail: Working on Zendesk's core data platform.
    i18n: company_a_desc
  date:
    detail: Oct. 2022 - Present
    i18n: company_a_date
  job:
    detail: Staff Data Engineer (promoted)
    i18n: company_a_job
  icon: fa-plus-square

- name:
    detail: Zendesk
    i18n: company_a
  desc:
    detail: Building data products within the Enterprise Data & Analytics org. 
            (Offering internal teams access to product data at scale, 
            contributing to the design and implementation of data domains,
            enhancing the existing data stack)
    i18n: company_a_desc
  date:
    detail: Nov. 2021 - Oct. 2022
    i18n: company_a_date
  job:
    detail: Senior Data Engineer
    i18n: company_a_job
  icon: fa-plus-square

- name:
    detail: FactSet
    i18n: company_a
  desc:
    detail: Worked on multiple projects on the AWS cloud (desiged and implemented cloud-based data lakes, data pipelines, and ML Ops pipelines).
            Designed and implemented an Apache Superset environment used by multiple teams within the company.
    i18n: company_b_desc
  date:
    detail: Apr. 2020 - Nov. 2021
    i18n: company_b_date
  job:
    detail: Data Engineer
    i18n: company_b_job
  icon: fa-plus-square

- name:
    detail: Cr√©dit Agricole CIB
    i18n: company_b
  desc:
    detail: Worked as a consultant with CA-CIB's data teams on implementing a Big Data architecture for the FRTB regulations.
            The project consisted of building a Hadoop data lake to store all of the bank's markets risk data.
    i18n: company_b_desc
  date:
    detail: Dec. 2018 - Apr. 2020
    i18n: company_b_date
  job:
    detail: Big Data Consultant
    i18n: company_b_job
  icon: fa-plus-square

- name:
    detail: Numberly
    i18n: company_b
  desc:
    detail: Worked at Numberly (1000mercis group) as a data engineer for my end-of-studies project. The project consisted of building
            data pipelines for a Big Data architecture using Apache Spark (PySpark), Apache Airflow, and Apache Zeppelin.
            The data was mainly stored on MSSQL and Apache Hive (on top of Apache Hadoop).
    i18n: company_a_desc
  date:
    detail: Jan. 2018 - Jul. 2018
    i18n: company_a_date
  job:
    detail: Big Data Developer
    i18n: company_a_job
  icon: fa-plus-square

- name:
    detail: Democracy International
    i18n: company_a
  desc:
    detail: Worked at Democracy International on a campaign to deliver useful information to Tunisian voters
            to motivate them to participate in the country's upcoming municipal elections.
            Turned the data provided by Tunisian ministries and associations into interactive 
            visualizations that helped voters get a better understanding of their municipalities' data.
    i18n: company_b_desc
  date:
    detail: May. 2017 - Jan. 2018
    i18n: company_b_date
  job:
    detail: Data Visualization Specialist
    i18n: company_b_job
  icon: fa-plus-square
